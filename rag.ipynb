{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример сервиса с использованием RAG для вопросно-ответной системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup:\n",
    "\n",
    "1. В этом руководстве для выполнения некоторых метрик используется OpenAI, поэтому убедитесь, что ваш ключ OpenAI готов и доступен в вашей среде.\n",
    "2. Вставте Ваш ключ для OpenAI в вайл 'env.txt'\n",
    "3. Установите нужные библиотеки. Рекомендуется использовать изолированое пространство (virtual environment).\n",
    "    * pip install -r requirements.txt\n",
    "4. запускайте блокнот"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пайплайн\n",
    "\n",
    "![rag_pipeline](data/rag_pipeline.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from dotenv import dotenv_values\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key successfully loaded\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from env.txt file\n",
    "env_vars = dotenv_values('env.txt')\n",
    "\n",
    "# Explicitly set the environment variables from the env.txt file to override the global variables if set\n",
    "for key, value in env_vars.items():\n",
    "    os.environ[key] = value\n",
    "\n",
    "# Verify the environment variables are set correctly\n",
    "if 'OPENAI_API_KEY' in os.environ:\n",
    "    print(f\"OpenAI API Key successfully loaded\")\n",
    "else:\n",
    "    print(\"Failed to load OpenAI API Key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка документов: \n",
    "\n",
    "LangChain предоставляет несколько встроенных загрузчиков документов, которые работают с PDF-файлами, JSON-файлами или Python-файлами в вашей файловой директории.  Мы можем использовать PyPDFLoader от LangChain, чтобы импортировать PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load document\n",
    "loader = PyPDFLoader(\"data/HAI_AI-Index-Report-2024_Chapter1.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение документов на куски (chunking):\n",
    "\n",
    "Когда документ длинный, необходимо разделить его на части. Существуют различные способы разделения текста. Давайте воспользуемся простейшим методом CharacterTextSplitter, который разделяет текст по символам и измеряет длину фрагмента по количеству символов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the documents into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание текстовых эмбеддингов: \n",
    "\n",
    "Затем текстовые фрагменты переводятся в числовые векторы с помощью эмбеддингов, что позволяет нам работать с текстовыми данными, как при семантическом поиске, эффективным с вычислительной точки зрения образом. Для этой задачи мы можем выбрать, например, OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which embeddings we want to use\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание хранилища векторов:\n",
    "\n",
    "Затем нам нужно сохранить векторы эмбеддинга в векторном хранилище, которое позволит нам искать и извлекать соответствующие векторы во время запросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the vectorestore to use as the index\n",
    "db = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание интерфейса ретривера: \n",
    "\n",
    "Мы можем представить хранилище векторов в интерфейсе ретривера. Чтобы получить текст, мы можем выбрать тип поиска, например « similarity», чтобы использовать поиск по сходству в объекте retriever, где он выбирает векторы текстовых фрагментов, которые наиболее похожи на вектор вопроса. k=2 позволяет нам найти 2 наиболее релевантных вектора текстовых фрагментов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expose this index in a retriever interface\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание цепочки RetrievalQA для ответов на вопросы: \n",
    "\n",
    "Цепочка RetrievalQA связывает большую языковую модель с нашим интерфейсом ретривера. \n",
    "\n",
    "Вы также можете указать тип цепочки как один из четырех вариантов:\n",
    "\n",
    "* stuff\n",
    "* map reduce\n",
    "* refine\n",
    "* map_rerank\n",
    "    \n",
    "\n",
    "1. Тип цепочки по умолчанию = «stuff» включает в запрос ВЕСЬ текст из документов.\n",
    "\n",
    "2. Тип «map_reduce» разбивает тексты на группы, задает вопрос LLM для каждой группы отдельно и выводит окончательный ответ, основываясь на ответах каждой группы. \n",
    "\n",
    "3. Тип «refine» разбивает тексты на блоки, представляет первый блок LLM, а затем отправляет ответ вместе со вторым блоком LLM. Он постепенно уточняет ответ, обрабатывая все батчи. \n",
    "\n",
    "4. Тип «map-rerank» делит тексты на блоки, представляет каждый из них в LLM, возвращает оценку, показывающую, насколько полно он отвечает на вопрос, и определяет окончательный ответ, основываясь на ответах, получивших наибольшее количество баллов из каждого блока."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a chain to answer questions\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(),\n",
    "    chain_type=\"map_reduce\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=True, # logging\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []\n",
    "rag_answers = []\n",
    "contexts = []\n",
    "naive_llm_answers = []\n",
    "ground_truths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_info(result, query_list, rag_answer_list, context_list):\n",
    "    query_list.append(result[\"query\"])\n",
    "    rag_answer_list.append(result[\"result\"])\n",
    "    current_contexts = []\n",
    "    for document in result[\"source_documents\"]:\n",
    "        current_contexts.append(document.page_content)\n",
    "    context_list.append(current_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'In which year the Ecosystem Graphs were introduced?',\n",
       " 'result': ' The Ecosystem Graphs were introduced in 2022.',\n",
       " 'source_documents': [Document(page_content='49\\nArtificial Intelligence\\nIndex Report 2024 Chapter 1 PreviewArtificial Intelligence\\nIndex Report 2024\\nlevel.7 CSET extracted year values from the first \\npublication date within a family. Countries are assigned \\nto patents based on the country or filing office where \\na patent is first filed (e.g., if a patent is filed with the \\nUSPTO on January 1, 2020, and then with the German \\nPatenting Office on January 2, 2020, the patent is \\nclassified as a patent with U.S. inventors).8 Note that \\nthe same patent may have multiple countries (but not \\nyears) attributed to it if the inventors filed their patent \\nin multiple countries on the same first filing date (e.g., \\nif a patent is filed with the USPTO on January 1, 2020, \\nand then with the German Patenting Office on January \\n1, 2020, the patent is classified as a patent with U.S. \\ninventors and as a patent with German inventors).\\nNote that patents filed with supranational \\norganizations, such as patents filed under WIPO (the \\nWorld Intellectual Property Organization), EP (European \\nPatent Organization), and EA (a special area of Spain \\nnot included in the European Union), also fall under the \\n“Rest of World” category.\\nEcosystems Graph Analysis\\nTo track the distribution of AI foundation models by \\ncountry, the AI Index team took the following steps:\\n 1.  A snapshot of the Ecosystems Graph was taken in \\nearly January 2024. \\n 2.  Authors of foundation models are attributed to \\ncountries based on their affiliation credited on \\nthe paper/technical documentation associated \\nwith the model. For international organizations, \\nauthors are attributed to the country where the \\norganization is headquartered, unless a more \\nspecific location is indicated. 3.  All of the landmark publications are \\naggregated within time periods (e.g., monthly \\nor yearly) with the national contributions \\nadded up to determine what each country’s \\ncontribution to landmark AI research was \\nduring each time period.\\n 4.  The contributions of different countries are \\ncompared over time to identify any trends.\\nEpoch Notable Models \\nAnalysis\\nThe AI forecasting research group Epoch maintains \\na dataset of landmark AI and ML models, along with \\naccompanying information about their creators and \\npublications, such as the list of their (co)authors, \\nnumber of citations, type of AI task accomplished, \\nand amount of compute used in training.\\nThe nationalities of the authors of these papers have \\nimportant implications for geopolitical AI forecasting. \\nAs various research institutions and technology \\ncompanies start producing advanced ML models, the \\nglobal distribution of future AI development may shift \\nor concentrate in certain places, which in turn affects \\nthe geopolitical landscape because AI is expected \\nto become a crucial component of economic and \\nmilitary power in the near future.\\nTo track the distribution of AI research contributions \\non landmark publications by country, the Epoch \\ndataset is coded according to the following \\nmethodology:\\n8 In CSET’s data analysis for the 2022 AI Index, we used the most recent publication date for a patent family. This method has the advantage of capturing updates within a patent \\nfamily (such as amendments). However, to remain consistent with CSET’s other data products, including the Country Activity Tracker (available at https:/ /cat.eto.tech/), we opted to \\nuse the first filing year instead in this data analysis.AppendixChapter 1: Research and Development', metadata={'page': 48, 'source': 'data/HAI_AI-Index-Report-2024_Chapter1.pdf'}),\n",
       "  Document(page_content='50\\nArtificial Intelligence\\nIndex Report 2024 Chapter 1 PreviewArtificial Intelligence\\nIndex Report 2024\\n 1.  A snapshot of the dataset was taken on \\nJanuary 1, 2024. This includes papers \\nabout landmark models, selected using the \\ninclusion criteria of importance, relevance, \\nand uniqueness, as described in the Compute \\nTrends dataset documentation.\\n 2.  The authors are attributed to countries based \\non their affiliation credited on the paper. \\nFor international organizations, authors \\nare attributed to the country where the \\norganization is headquartered, unless a more \\nspecific location is indicated.\\n 3.  All of the landmark publications are \\naggregated within time periods (e.g., monthly \\nor yearly) with the national contributions \\nadded up to determine what each country’s \\ncontribution to landmark AI research was \\nduring each time period.\\n 4.  The contributions of different countries are \\ncompared over time to identify any trends.\\nGitHub\\nIdentifying AI Projects  \\nIn partnership with researchers from Harvard Business \\nSchool, Microsoft Research, and Microsoft’s AI for \\nGood Lab, GitHub identifies public AI repositories \\nfollowing the methodologies of Gonzalez, Zimmerman, \\nand Nagappan, 2020 , and Dohmke, Iansiti, and \\nRichards, 2023 , using topic labels related to AI/ML \\nand generative AI, respectively, along with the topics \\n“machine learning,” “deep learning,” or “artificial \\nintelligence.” GitHub further augments the dataset with \\nrepositories that have a dependency on the PyTorch, \\nTensorFlow, or OpenAI libraries for Python.Mapping AI Projects to Geographic Areas  \\nPublic AI projects are mapped to geographic areas \\nusing IP address geolocation to determine the mode \\nlocation of a project’s owners each year. Each project \\nowner is assigned a location based on their IP address \\nwhen interacting with GitHub. If a project owner \\nchanges locations within a year, the location for the \\nproject would be determined by the mode location \\nof its owners sampled daily in the year. Additionally, \\nthe last known location of the project owner is \\ncarried forward on a daily basis even if no activities \\nwere performed by the project owner that day. For \\nexample, if a project owner performed activities \\nwithin the United States and then became inactive for \\nsix days, that project owner would be considered to \\nbe in the United States for that seven-day span.\\nTraining Cost Analysis\\nTo create the dataset of cost estimates, the Epoch \\ndatabase was filtered for models released during the \\nlarge-scale ML era9 that were above the median of \\ntraining compute in a two-year window centered on \\ntheir release date. This filtered for the largest-scale \\nML models. There were 138 qualifying systems based \\non these criteria. Of these systems, 48 had sufficient \\ninformation to estimate the training cost.\\nFor the selected ML models, the training time and \\nthe type, quantity, and utilization rate of the training \\nhardware were determined from the publication, \\npress release, or technical reports, as applicable. \\nCloud rental prices for the computing hardware used \\nby these models were collected from online historical \\narchives of cloud vendors’ websites.10\\n9 The selected cutoff date was September 1, 2015, in accordance with Compute Trends Across Three Eras of Machine Learning (Epoch, 2022).\\n10 Historic prices were collected from archived snapshots of Amazon Web Services, Microsoft Azure, and Google Cloud Platform price catalogs viewed through the Internet Archive \\nWayback Machine.AppendixChapter 1: Research and Development', metadata={'page': 49, 'source': 'data/HAI_AI-Index-Report-2024_Chapter1.pdf'})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain.invoke(\"In which year the Ecosystem Graphs were introduced?\")\n",
    "\n",
    "# store information for evaluation dataset\n",
    "collect_info(result, queries, rag_answers, contexts)\n",
    "ground_truths.append(\"2023\")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 48, 'source': 'data/HAI_AI-Index-Report-2024_Chapter1.pdf'}\n",
      "++++++++++++++++++++++++++\n",
      "49\n",
      "Artificial Intelligence\n",
      "Index Report 2024 Chapter 1 PreviewArtificial Intelligence\n",
      "Index Report 2024\n",
      "level.7 CSET extracted year values from the first \n",
      "publication date within a family. Countries are assigned \n",
      "to patents based on the country or filing office where \n",
      "a patent is first filed (e.g., if a patent is filed with the \n",
      "USPTO on January 1, 2020, and then with the German \n",
      "Patenting Office on January 2, 2020, the patent is \n",
      "classified as a patent with U.S. inventors).8 Note that \n",
      "the same patent may have multiple countries (but not \n",
      "years) attributed to it if the inventors filed their patent \n",
      "in multiple countries on the same first filing date (e.g., \n",
      "if a patent is filed with the USPTO on January 1, 2020, \n",
      "and then with the German Patenting Office on January \n",
      "1, 2020, the patent is classified as a patent with U.S. \n",
      "inventors and as a patent with German inventors).\n",
      "Note that patents filed with supranational \n",
      "organizations, such as patents filed under WIPO (the \n",
      "World Intellectual Property Organization), EP (European \n",
      "Patent Organization), and EA (a special area of Spain \n",
      "not included in the European Union), also fall under the \n",
      "“Rest of World” category.\n",
      "Ecosystems Graph Analysis\n",
      "To track the distribution of AI foundation models by \n",
      "country, the AI Index team took the following steps:\n",
      " 1.  A snapshot of the Ecosystems Graph was taken in \n",
      "early January 2024. \n",
      " 2.  Authors of foundation models are attributed to \n",
      "countries based on their affiliation credited on \n",
      "the paper/technical documentation associated \n",
      "with the model. For international organizations, \n",
      "authors are attributed to the country where the \n",
      "organization is headquartered, unless a more \n",
      "specific location is indicated. 3.  All of the landmark publications are \n",
      "aggregated within time periods (e.g., monthly \n",
      "or yearly) with the national contributions \n",
      "added up to determine what each country’s \n",
      "contribution to landmark AI research was \n",
      "during each time period.\n",
      " 4.  The contributions of different countries are \n",
      "compared over time to identify any trends.\n",
      "Epoch Notable Models \n",
      "Analysis\n",
      "The AI forecasting research group Epoch maintains \n",
      "a dataset of landmark AI and ML models, along with \n",
      "accompanying information about their creators and \n",
      "publications, such as the list of their (co)authors, \n",
      "number of citations, type of AI task accomplished, \n",
      "and amount of compute used in training.\n",
      "The nationalities of the authors of these papers have \n",
      "important implications for geopolitical AI forecasting. \n",
      "As various research institutions and technology \n",
      "companies start producing advanced ML models, the \n",
      "global distribution of future AI development may shift \n",
      "or concentrate in certain places, which in turn affects \n",
      "the geopolitical landscape because AI is expected \n",
      "to become a crucial component of economic and \n",
      "military power in the near future.\n",
      "To track the distribution of AI research contributions \n",
      "on landmark publications by country, the Epoch \n",
      "dataset is coded according to the following \n",
      "methodology:\n",
      "8 In CSET’s data analysis for the 2022 AI Index, we used the most recent publication date for a patent family. This method has the advantage of capturing updates within a patent \n",
      "family (such as amendments). However, to remain consistent with CSET’s other data products, including the Country Activity Tracker (available at https:/ /cat.eto.tech/), we opted to \n",
      "use the first filing year instead in this data analysis.AppendixChapter 1: Research and Development\n",
      "==========================\n",
      "{'page': 49, 'source': 'data/HAI_AI-Index-Report-2024_Chapter1.pdf'}\n",
      "++++++++++++++++++++++++++\n",
      "50\n",
      "Artificial Intelligence\n",
      "Index Report 2024 Chapter 1 PreviewArtificial Intelligence\n",
      "Index Report 2024\n",
      " 1.  A snapshot of the dataset was taken on \n",
      "January 1, 2024. This includes papers \n",
      "about landmark models, selected using the \n",
      "inclusion criteria of importance, relevance, \n",
      "and uniqueness, as described in the Compute \n",
      "Trends dataset documentation.\n",
      " 2.  The authors are attributed to countries based \n",
      "on their affiliation credited on the paper. \n",
      "For international organizations, authors \n",
      "are attributed to the country where the \n",
      "organization is headquartered, unless a more \n",
      "specific location is indicated.\n",
      " 3.  All of the landmark publications are \n",
      "aggregated within time periods (e.g., monthly \n",
      "or yearly) with the national contributions \n",
      "added up to determine what each country’s \n",
      "contribution to landmark AI research was \n",
      "during each time period.\n",
      " 4.  The contributions of different countries are \n",
      "compared over time to identify any trends.\n",
      "GitHub\n",
      "Identifying AI Projects  \n",
      "In partnership with researchers from Harvard Business \n",
      "School, Microsoft Research, and Microsoft’s AI for \n",
      "Good Lab, GitHub identifies public AI repositories \n",
      "following the methodologies of Gonzalez, Zimmerman, \n",
      "and Nagappan, 2020 , and Dohmke, Iansiti, and \n",
      "Richards, 2023 , using topic labels related to AI/ML \n",
      "and generative AI, respectively, along with the topics \n",
      "“machine learning,” “deep learning,” or “artificial \n",
      "intelligence.” GitHub further augments the dataset with \n",
      "repositories that have a dependency on the PyTorch, \n",
      "TensorFlow, or OpenAI libraries for Python.Mapping AI Projects to Geographic Areas  \n",
      "Public AI projects are mapped to geographic areas \n",
      "using IP address geolocation to determine the mode \n",
      "location of a project’s owners each year. Each project \n",
      "owner is assigned a location based on their IP address \n",
      "when interacting with GitHub. If a project owner \n",
      "changes locations within a year, the location for the \n",
      "project would be determined by the mode location \n",
      "of its owners sampled daily in the year. Additionally, \n",
      "the last known location of the project owner is \n",
      "carried forward on a daily basis even if no activities \n",
      "were performed by the project owner that day. For \n",
      "example, if a project owner performed activities \n",
      "within the United States and then became inactive for \n",
      "six days, that project owner would be considered to \n",
      "be in the United States for that seven-day span.\n",
      "Training Cost Analysis\n",
      "To create the dataset of cost estimates, the Epoch \n",
      "database was filtered for models released during the \n",
      "large-scale ML era9 that were above the median of \n",
      "training compute in a two-year window centered on \n",
      "their release date. This filtered for the largest-scale \n",
      "ML models. There were 138 qualifying systems based \n",
      "on these criteria. Of these systems, 48 had sufficient \n",
      "information to estimate the training cost.\n",
      "For the selected ML models, the training time and \n",
      "the type, quantity, and utilization rate of the training \n",
      "hardware were determined from the publication, \n",
      "press release, or technical reports, as applicable. \n",
      "Cloud rental prices for the computing hardware used \n",
      "by these models were collected from online historical \n",
      "archives of cloud vendors’ websites.10\n",
      "9 The selected cutoff date was September 1, 2015, in accordance with Compute Trends Across Three Eras of Machine Learning (Epoch, 2022).\n",
      "10 Historic prices were collected from archived snapshots of Amazon Web Services, Microsoft Azure, and Google Cloud Platform price catalogs viewed through the Internet Archive \n",
      "Wayback Machine.AppendixChapter 1: Research and Development\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "for document in result[\"source_documents\"]:\n",
    "    print(document.metadata)\n",
    "    print(\"++++++++++++++++++++++++++\")\n",
    "    print(document.page_content)\n",
    "    print(\"==========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'page': 36, 'source': 'data/HAI_AI-Index-Report-2024_Chapter1.pdf'}\n",
      "{'page': 37, 'source': 'data/HAI_AI-Index-Report-2024_Chapter1.pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What was the training cost of GPT-4?',\n",
       " 'result': ' The training cost for GPT-4 was mentioned to be over $100 million.',\n",
       " 'source_documents': [Document(page_content='Chapter 1 Preview 37\\nArtificial Intelligence\\nIndex Report 2024Training Cost\\nA prominent topic in discussions about foundation \\nmodels is their speculated costs. While AI \\ncompanies seldom reveal the expenses involved \\nin training their models, it is widely believed that \\nthese costs run into millions of dollars and are \\nrising. For instance, OpenAI’s CEO, Sam Altman, \\nmentioned that the training cost for GPT-4 was over \\n$100 million. This escalation in training expenses \\nhas effectively excluded universities, traditionally \\ncenters of AI research, from developing their own \\nleading-edge foundation models. In response, policy \\ninitiatives, such as President Biden’s Executive Order \\non AI , have sought to level the playing field between \\nindustry and academia by creating a National AI \\nResearch Resource, which would grant nonindustry \\nactors the compute and data needed to do higher \\nlevel AI-research.\\nUnderstanding the cost of training AI models is \\nimportant, yet detailed information on these costs \\nremains scarce. The AI Index was among the first to \\noffer estimates on the training costs of foundation models in last year’s publication. This year, the AI \\nIndex has collaborated with Epoch AI , an AI research \\ninstitute, to substantially enhance and solidify the \\nrobustness of its AI training cost estimates.9 To \\nestimate the cost of cutting-edge models, the Epoch \\nteam analyzed training duration, as well as the type, \\nquantity, and utilization rate of the training hardware, \\nusing information from publications, press releases, or \\ntechnical reports related to the models.10\\nFigure 1.3.21 visualizes the estimated training cost \\nassociated with select AI models, based on cloud \\ncompute rental prices. AI Index estimates validate \\nsuspicions that in recent years model training costs \\nhave significantly increased. For example, in 2017, \\nthe original Transformer model, which introduced the \\narchitecture that underpins virtually every modern \\nLLM, cost around $900 to train.11 RoBERTa Large, \\nreleased in 2019, which achieved state-of-the-art \\nresults on many canonical comprehension benchmarks \\nlike SQuAD and GLUE, cost around $160,000 to train. \\nFast-forward to 2023, and training costs for OpenAI’s \\nGPT-4 and Google’s Gemini Ultra are estimated to be \\naround $78 million and $191 million, respectively.1.3 Frontier AI ResearchChapter 1: Research and Development Artificial Intelligence\\nIndex Report 2024\\n9 Ben Cottier and Robi Rahman led research at Epoch AI into model training cost.\\n10 A detailed description of the estimation methodology is provided in the Appendix.\\n11 The cost figures reported in this section are inflation-adjusted.', metadata={'page': 36, 'source': 'data/HAI_AI-Index-Report-2024_Chapter1.pdf'}),\n",
       "  Document(page_content='Chapter 1 Preview 38\\nArtificial Intelligence\\nIndex Report 2024930 3,288 160,0184,32 4,883 6,405,6531,319,58612,389 ,05678,352, 034\\n3,931,897191,400,000Transf ormer\\nBERT -Large\\nRoBERT a Lar ge\\nGPT -3 175B (davinci)\\nMeg atron-Turing NL G 530B\\nLaMD A\\nPaLM ( 540B)\\nGPT -4\\nLlama 2 70B\\nGemini Ult ra\\n2017 2018 2019 2020 2021 2022 2023050M100M150M200MTraining c ost (in U .S. dollars)Estimated training c ost of s elect AI models, 20 17–23\\nSource: Epoch, 2023 | C hart: 202 4 AI Inde x repor t\\nGemini Ultra\\nFalcon 180B\\nStarCoderGPT-4\\nLLaMA-65BLlama 2 70B\\nBLOOM-176B\\nPaLI\\nImagenFlamingoPaLM (540B)\\nT0-XXLHyperCLOVA\\nMeta Pseudo LabelsSwitchGPT-3 175B (davinci)\\nAlphaStarMegatron-BERT\\nRoBERTa Large\\nSciBERTBERT-LargeBigGAN-deep 512×512\\nBig Transformer for Back-Translation\\nIMPALAJFT\\nTransformerXceptionGNMT\\n2016 2017 2018 2019 2020 2021 2022 2023100100010K100K1M10M100M\\nPublication dateTraining cost (in U.S. dollars - log scale)Estimated training cost of select AI models, 2016–23\\nSource: Epoch, 2023 | Chart: 2024 AI Index report1.3 Frontier AI ResearchChapter 1: Research and Development Artificial Intelligence\\nIndex Report 2024\\nFigure 1.3.21\\nFigure 1.3.22Figure 1.3.22 visualizes the training cost of all AI models for which the AI Index has estimates. As the figure shows, \\nmodel training costs have sharply increased over time.', metadata={'page': 37, 'source': 'data/HAI_AI-Index-Report-2024_Chapter1.pdf'})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain.invoke(\"What was the training cost of GPT-4?\")\n",
    "\n",
    "# store information for evaluation dataset\n",
    "collect_info(result, queries, rag_answers, contexts)\n",
    "ground_truths.append(\"over over 100 million Dollars\")\n",
    "for document in result[\"source_documents\"]:\n",
    "    print(document.metadata)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Давайте сгенерируем наивные ответы LLM с помощью OpenAI без нашего RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_naive_llm_response(question):\n",
    "    try:\n",
    "        chat_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": question,\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            stream=False, # usability vs. performance tradeoff\n",
    "            temperature=0.01,\n",
    "        )\n",
    "\n",
    "        if hasattr(chat_response, \"choices\"):\n",
    "            print(chat_response.choices[0].message.content.strip())\n",
    "            return chat_response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to generate response for question: {question}\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ecosystem Graphs were introduced in the year 2019.\n",
      "The training cost of GPT-4 is not publicly disclosed by OpenAI, the organization behind the development of the GPT series of models. However, it is estimated that training a large language model like GPT-4 could cost millions of dollars in terms of computational resources, electricity, and manpower.\n"
     ]
    }
   ],
   "source": [
    "for question in queries:\n",
    "    naive_llm_answers.append(generate_naive_llm_response(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas df from these lists\n",
    "my_general_ds = pd.DataFrame(\n",
    "    {\n",
    "        \"questions\": queries,\n",
    "        \"rag_answers\": rag_answers,\n",
    "        \"naive_llm_answers\": naive_llm_answers,\n",
    "        \"ground_truths\": ground_truths,\n",
    "        \"contexts\": contexts,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>rag_answers</th>\n",
       "      <th>naive_llm_answers</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In which year the Ecosystem Graphs were introduced?</td>\n",
       "      <td>The Ecosystem Graphs were introduced in 2022.</td>\n",
       "      <td>The Ecosystem Graphs were introduced in the year 2019.</td>\n",
       "      <td>2023</td>\n",
       "      <td>[49\\nArtificial Intelligence\\nIndex Report 2024 Chapter 1 PreviewArtificial Intelligence\\nIndex ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was the training cost of GPT-4?</td>\n",
       "      <td>The training cost for GPT-4 was mentioned to be over $100 million.</td>\n",
       "      <td>The training cost of GPT-4 is not publicly disclosed by OpenAI, the organization behind the deve...</td>\n",
       "      <td>over over 100 million Dollars</td>\n",
       "      <td>[Chapter 1 Preview 37\\nArtificial Intelligence\\nIndex Report 2024Training Cost\\nA prominent topi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             questions  \\\n",
       "0  In which year the Ecosystem Graphs were introduced?   \n",
       "1                 What was the training cost of GPT-4?   \n",
       "\n",
       "                                                           rag_answers  \\\n",
       "0                        The Ecosystem Graphs were introduced in 2022.   \n",
       "1   The training cost for GPT-4 was mentioned to be over $100 million.   \n",
       "\n",
       "                                                                                     naive_llm_answers  \\\n",
       "0                                               The Ecosystem Graphs were introduced in the year 2019.   \n",
       "1  The training cost of GPT-4 is not publicly disclosed by OpenAI, the organization behind the deve...   \n",
       "\n",
       "                   ground_truths  \\\n",
       "0                           2023   \n",
       "1  over over 100 million Dollars   \n",
       "\n",
       "                                                                                              contexts  \n",
       "0  [49\\nArtificial Intelligence\\nIndex Report 2024 Chapter 1 PreviewArtificial Intelligence\\nIndex ...  \n",
       "1  [Chapter 1 Preview 37\\nArtificial Intelligence\\nIndex Report 2024Training Cost\\nA prominent topi...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_general_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка наивных ответов LLM с помощью RAGAS\n",
    "\n",
    "дополнительные комментарии и пояснения смотрите в файле 'ragas_evaluation.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "from ragas import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: ragas documentation is not up to date (14.05.2024). The requred Dataset structure is:\n",
    "# Dataset.from_dict(\n",
    "#         {\n",
    "#             'question': list[str],\n",
    "#             'contexts': list[list[str]],\n",
    "#             'ground_truth': list[str],\n",
    "#             'answer': list[str]\n",
    "#         }\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_llm_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        'question': queries,\n",
    "        'contexts': contexts,\n",
    "        'ground_truth': ground_truths,\n",
    "        'answer': naive_llm_answers,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e0d85edb9a458fafad067d08567930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.5000, 'faithfulness': 0.3333, 'answer_relevancy': 0.9800, 'context_recall': 0.5000}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_result = evaluate(\n",
    "    naive_llm_dataset, \n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "naive_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In which year the Ecosystem Graphs were introduced?</td>\n",
       "      <td>[49\\nArtificial Intelligence\\nIndex Report 2024 Chapter 1 PreviewArtificial Intelligence\\nIndex ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>The Ecosystem Graphs were introduced in the year 2019.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982378</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was the training cost of GPT-4?</td>\n",
       "      <td>[Chapter 1 Preview 37\\nArtificial Intelligence\\nIndex Report 2024Training Cost\\nA prominent topi...</td>\n",
       "      <td>over over 100 million Dollars</td>\n",
       "      <td>The training cost of GPT-4 is not publicly disclosed by OpenAI, the organization behind the deve...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.977655</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0  In which year the Ecosystem Graphs were introduced?   \n",
       "1                 What was the training cost of GPT-4?   \n",
       "\n",
       "                                                                                              contexts  \\\n",
       "0  [49\\nArtificial Intelligence\\nIndex Report 2024 Chapter 1 PreviewArtificial Intelligence\\nIndex ...   \n",
       "1  [Chapter 1 Preview 37\\nArtificial Intelligence\\nIndex Report 2024Training Cost\\nA prominent topi...   \n",
       "\n",
       "                    ground_truth  \\\n",
       "0                           2023   \n",
       "1  over over 100 million Dollars   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                               The Ecosystem Graphs were introduced in the year 2019.   \n",
       "1  The training cost of GPT-4 is not publicly disclosed by OpenAI, the organization behind the deve...   \n",
       "\n",
       "   context_precision  faithfulness  answer_relevancy  context_recall  \n",
       "0                0.0      0.000000          0.982378             0.0  \n",
       "1                1.0      0.666667          0.977655             1.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naive = naive_result.to_pandas()\n",
    "df_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка ответов, сгенерированных с RAG с использованием RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        'question': queries,\n",
    "        'contexts': contexts,\n",
    "        'ground_truth': ground_truths,\n",
    "        'answer': rag_answers,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbeaafa285f549b299e981d8f4fac967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.5000, 'faithfulness': 0.5000, 'answer_relevancy': 0.9902, 'context_recall': 0.5000}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_result = evaluate(\n",
    "    RAG_dataset, \n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "rag_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In which year the Ecosystem Graphs were introduced?</td>\n",
       "      <td>[49\\nArtificial Intelligence\\nIndex Report 2024 Chapter 1 PreviewArtificial Intelligence\\nIndex ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>The Ecosystem Graphs were introduced in 2022.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982378</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was the training cost of GPT-4?</td>\n",
       "      <td>[Chapter 1 Preview 37\\nArtificial Intelligence\\nIndex Report 2024Training Cost\\nA prominent topi...</td>\n",
       "      <td>over over 100 million Dollars</td>\n",
       "      <td>The training cost for GPT-4 was mentioned to be over $100 million.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997954</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0  In which year the Ecosystem Graphs were introduced?   \n",
       "1                 What was the training cost of GPT-4?   \n",
       "\n",
       "                                                                                              contexts  \\\n",
       "0  [49\\nArtificial Intelligence\\nIndex Report 2024 Chapter 1 PreviewArtificial Intelligence\\nIndex ...   \n",
       "1  [Chapter 1 Preview 37\\nArtificial Intelligence\\nIndex Report 2024Training Cost\\nA prominent topi...   \n",
       "\n",
       "                    ground_truth  \\\n",
       "0                           2023   \n",
       "1  over over 100 million Dollars   \n",
       "\n",
       "                                                                answer  \\\n",
       "0                        The Ecosystem Graphs were introduced in 2022.   \n",
       "1   The training cost for GPT-4 was mentioned to be over $100 million.   \n",
       "\n",
       "   context_precision  faithfulness  answer_relevancy  context_recall  \n",
       "0                0.0           0.0          0.982378             0.0  \n",
       "1                1.0           1.0          0.997954             1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rag = rag_result.to_pandas()\n",
    "df_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
